{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Master-Shuvam/MultiTrack-Cricket/blob/main/Copy_of_23f3002495_UPDATED_PLAYER_TRACKING_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WELCOME TO THE HIGHLY STABILISED UPDATED PLAYER ID TRACKING SYSTEM\n",
        "\n",
        "‚úÖSTEPS TO RUN IT SMOOTHLY:\n",
        "1. Open the notebook in Google Colab\n",
        "2. Run all the cells at once\n",
        "3. Mount google drive for direct importing option from drive\n",
        "4. When prompted just enter the video file datapath\n",
        "5. Then just enjoy !!!!!!!! everything is automatic\n",
        "6. Automatic downloading will be done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xx2cidNzvNBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALL DEPENDENCIES WILL BE DOWLOADED HERE"
      ],
      "metadata": {
        "id": "p_6YnQofDt5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Run this cell first to install all required packages\n",
        "\"\"\"\n",
        "\n",
        "!pip install ultralytics -q\n",
        "!pip install supervision -q\n",
        "!pip install opencv-python-headless -q\n",
        "!pip install torch torchvision -q\n",
        "!pip install scipy -q\n",
        "\n",
        "print(\" All dependencies installed successfully!\")"
      ],
      "metadata": {
        "id": "yE14eYiOIAZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNT GOOGLE DRIVE DIRECTLY IN COLAB"
      ],
      "metadata": {
        "id": "6jpqIyKnA8gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict, deque\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úì Libraries imported and Drive mounted successfully!\")\n",
        "print(f\"‚úì Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
      ],
      "metadata": {
        "id": "1uMkg1mCASdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MY SPECIALLY DESIGNED CUSTOM ENGINEERED SPATIAL ANCHORED MULTI-FEATURE TRACKER FOR LONG TERM ID STABILITY"
      ],
      "metadata": {
        "id": "K970LAiqBD7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgXEkSHZH6TL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SPATIAL ANCHORED PLAYER TRACKER\n",
        "================================\n",
        "Key Innovation: Players CANNOT teleport!\n",
        "- Enforces spatial continuity\n",
        "- Maximum 12 active players (11 players + extras)\n",
        "- ID created ONLY if far from ALL existing players\n",
        "- Strong temporal memory (20 frames)\n",
        "- Multi-feature matching (position, size, color, speed, direction)\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "class SpatialAnchoredTracker:\n",
        "\n",
        "    def __init__(self, max_players=12, spatial_threshold=300, memory_frames=30):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_players: Maximum players on field (11 players + buffer)\n",
        "            spatial_threshold: Minimum distance for new ID (pixels)\n",
        "            memory_frames: Number of frames to remember per track\n",
        "        \"\"\"\n",
        "        self.max_players = max_players\n",
        "        self.spatial_threshold = spatial_threshold  # New ID only if > 300px away\n",
        "        self.memory_frames = memory_frames\n",
        "\n",
        "        self.next_id = 1\n",
        "        self.active_tracks = {}  # Currently visible players\n",
        "        self.memory_bank = {}    # Recently lost players (keep for recovery)\n",
        "        self.frame_count = 0\n",
        "\n",
        "        # ID STABILITY ENHANCEMENT\n",
        "        self.track_confidence = {}  # Track how stable each ID is\n",
        "        self.last_match_quality = {}  # Quality of last match for each track\n",
        "\n",
        "        print(f\"‚úì Spatial Anchored Tracker initialized:\")\n",
        "        print(f\"  - Max Players: {max_players}\")\n",
        "        print(f\"  - Spatial Threshold: {spatial_threshold}px\")\n",
        "        print(f\"  - Memory Frames: {memory_frames}\")\n",
        "\n",
        "    def _extract_features(self, frame, box):\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "        h, w = frame.shape[:2]\n",
        "        x1 = max(0, min(x1, w-1))\n",
        "        y1 = max(0, min(y1, h-1))\n",
        "        x2 = max(0, min(x2, w-1))\n",
        "        y2 = max(0, min(y2, h-1))\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            roi = frame[y1:y2, x1:x2]\n",
        "            if roi.size == 0:\n",
        "                return None\n",
        "\n",
        "            # Multi-space color histograms\n",
        "            roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "            hist_h = cv2.calcHist([roi_hsv], [0], None, [30], [0, 180])\n",
        "            hist_s = cv2.calcHist([roi_hsv], [1], None, [32], [0, 256])\n",
        "\n",
        "            hist_h = cv2.normalize(hist_h, hist_h).flatten()\n",
        "            hist_s = cv2.normalize(hist_s, hist_s).flatten()\n",
        "\n",
        "            features = np.concatenate([hist_h, hist_s])\n",
        "            return features\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _compare_features(self, feat1, feat2):\n",
        "\n",
        "        if feat1 is None or feat2 is None:\n",
        "            return 0.0\n",
        "\n",
        "        similarity = np.corrcoef(feat1, feat2)[0, 1]\n",
        "        if np.isnan(similarity):\n",
        "            return 0.0\n",
        "\n",
        "        return max(0, min(1, (similarity + 1) / 2))\n",
        "\n",
        "    def _get_center(self, box):\n",
        "\n",
        "        return np.array([(box[0] + box[2]) / 2, (box[1] + box[3]) / 2])\n",
        "\n",
        "    def _get_size(self, box):\n",
        "\n",
        "        return (box[2] - box[0]) * (box[3] - box[1])\n",
        "\n",
        "    def _calculate_distance(self, box1, box2):\n",
        "\n",
        "        c1 = self._get_center(box1)\n",
        "        c2 = self._get_center(box2)\n",
        "        return np.linalg.norm(c1 - c2)\n",
        "\n",
        "    def _calculate_iou(self, box1, box2):\n",
        "\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "\n",
        "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        area1 = self._get_size(box1)\n",
        "        area2 = self._get_size(box2)\n",
        "        union = area1 + area2 - intersection\n",
        "\n",
        "        return intersection / union if union > 0 else 0.0\n",
        "\n",
        "    def _predict_next_position(self, track):\n",
        "\n",
        "        positions = track['position_history']\n",
        "\n",
        "        if len(positions) < 2:\n",
        "            return track['box']\n",
        "\n",
        "        # Use last 5 positions for prediction\n",
        "        recent = list(positions)[-5:]\n",
        "        centers = np.array([self._get_center(box) for box in recent])\n",
        "\n",
        "        if len(centers) >= 3:\n",
        "            # Fit motion model\n",
        "            velocities = np.diff(centers, axis=0)\n",
        "            avg_velocity = np.mean(velocities[-3:], axis=0)\n",
        "\n",
        "            # Predict with damping\n",
        "            last_center = centers[-1]\n",
        "            predicted_center = last_center + avg_velocity * 1.2\n",
        "\n",
        "            # Build predicted box\n",
        "            last_box = recent[-1]\n",
        "            w, h = last_box[2] - last_box[0], last_box[3] - last_box[1]\n",
        "\n",
        "            predicted_box = np.array([\n",
        "                predicted_center[0] - w/2,\n",
        "                predicted_center[1] - h/2,\n",
        "                predicted_center[0] + w/2,\n",
        "                predicted_center[1] + h/2\n",
        "            ])\n",
        "\n",
        "            return predicted_box\n",
        "\n",
        "        return np.array(track['box'])\n",
        "\n",
        "    def _calculate_match_score(self, detection, track, det_feature):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive match score with ID STABILITY BOOST\n",
        "\n",
        "        Considers:\n",
        "        - Spatial distance (position continuity)\n",
        "        - IoU (overlap)\n",
        "        - Appearance (color similarity)\n",
        "        - Size consistency\n",
        "        - Speed consistency\n",
        "        - Direction consistency\n",
        "        - TRACK CONFIDENCE (new - rewards stable tracks)\n",
        "        \"\"\"\n",
        "        det_box = detection[:4]\n",
        "        pred_box = self._predict_next_position(track)\n",
        "\n",
        "        # 1. Spatial distance (MOST IMPORTANT - no teleportation!)\n",
        "        distance = self._calculate_distance(det_box, pred_box)\n",
        "\n",
        "        # ADAPTIVE distance threshold based on track stability\n",
        "        track_id = None\n",
        "        for tid, t in self.active_tracks.items():\n",
        "            if t == track:\n",
        "                track_id = tid\n",
        "                break\n",
        "\n",
        "\n",
        "        confidence = self.track_confidence.get(track_id, 0.5)\n",
        "        max_expected_distance = 150 + (confidence * 150)  # 150-300px based on stability\n",
        "\n",
        "        spatial_score = max(0, 1 - distance / max_expected_distance)\n",
        "\n",
        "        # 2. IoU\n",
        "        iou = self._calculate_iou(det_box, pred_box)\n",
        "\n",
        "        # 3. Appearance\n",
        "        appearance_score = self._compare_features(det_feature, track['appearance'])\n",
        "\n",
        "        # 4. Size consistency\n",
        "        det_size = self._get_size(det_box)\n",
        "        track_size = np.mean([self._get_size(b) for b in list(track['position_history'])[-5:]])\n",
        "        size_ratio = min(det_size, track_size) / max(det_size, track_size, 1)\n",
        "\n",
        "        # 5. Speed consistency\n",
        "        speed_score = 1.0\n",
        "        if len(track['position_history']) >= 2:\n",
        "            recent_speeds = []\n",
        "            positions = list(track['position_history'])[-5:]\n",
        "            for i in range(1, len(positions)):\n",
        "                dist = self._calculate_distance(positions[i], positions[i-1])\n",
        "                recent_speeds.append(dist)\n",
        "\n",
        "            if recent_speeds:\n",
        "                avg_speed = np.mean(recent_speeds)\n",
        "                current_speed = distance\n",
        "\n",
        "                if avg_speed > 0:\n",
        "                    speed_ratio = min(current_speed, avg_speed) / max(current_speed, avg_speed)\n",
        "                    speed_score = speed_ratio\n",
        "\n",
        "        # 6. Direction consistency\n",
        "        direction_score = 1.0\n",
        "        if len(track['position_history']) >= 3:\n",
        "            positions = list(track['position_history'])[-5:]\n",
        "            centers = np.array([self._get_center(box) for box in positions])\n",
        "\n",
        "            if len(centers) >= 2:\n",
        "                prev_direction = centers[-1] - centers[-2]\n",
        "                det_center = self._get_center(det_box)\n",
        "                pred_center = self._get_center(pred_box)\n",
        "                current_direction = det_center - pred_center\n",
        "\n",
        "                if np.linalg.norm(prev_direction) > 0 and np.linalg.norm(current_direction) > 0:\n",
        "                    # Cosine similarity\n",
        "                    cos_sim = np.dot(prev_direction, current_direction) / (\n",
        "                        np.linalg.norm(prev_direction) * np.linalg.norm(current_direction)\n",
        "                    )\n",
        "                    direction_score = (cos_sim + 1) / 2\n",
        "\n",
        "\n",
        "        stability_bonus = confidence * 0.3  # Up to 30% boost!\n",
        "\n",
        "        # 8. Recent match quality - if last match was good, boost this match\n",
        "        last_quality = self.last_match_quality.get(track_id, 0.5)\n",
        "        quality_bonus = last_quality * 0.1  # Up to 10% boost\n",
        "\n",
        "        # Weighted combination - HEAVILY FAVOR STABLE TRACKS\n",
        "        base_score = (\n",
        "            0.35 * spatial_score +      # Position continuity\n",
        "            0.25 * appearance_score +   # Visual similarity\n",
        "            0.15 * iou +                # Overlap\n",
        "            0.10 * size_ratio +         # Size consistency\n",
        "            0.08 * speed_score +        # Speed consistency\n",
        "            0.07 * direction_score      # Direction consistency\n",
        "        )\n",
        "\n",
        "        # Add stability bonuses\n",
        "        final_score = base_score + stability_bonus + quality_bonus\n",
        "\n",
        "        return final_score, distance\n",
        "\n",
        "    def _is_far_from_all_tracks(self, detection_box, threshold):\n",
        "        \"\"\"\n",
        "        Check if detection is far from ALL existing tracks\n",
        "        This prevents creating new IDs for existing players\n",
        "        \"\"\"\n",
        "        if not self.active_tracks:\n",
        "            return True\n",
        "\n",
        "        det_center = self._get_center(detection_box)\n",
        "\n",
        "        for track in self.active_tracks.values():\n",
        "            track_box = track['box']\n",
        "            if isinstance(track_box, list):\n",
        "                track_box = np.array(track_box)\n",
        "            track_center = self._get_center(track_box)\n",
        "            distance = np.linalg.norm(det_center - track_center)\n",
        "\n",
        "            if distance < threshold:\n",
        "                return False  # Too close to existing player\n",
        "\n",
        "        return True  # Far from all players\n",
        "\n",
        "    def update(self, detections, frame=None):\n",
        "        \"\"\"\n",
        "        Update tracker with spatial anchoring\n",
        "\n",
        "        Strategy:\n",
        "        1. Match detections to existing tracks (strict matching)\n",
        "        2. Try to recover from memory bank\n",
        "        3. Only create new ID if:\n",
        "           - Far from ALL existing players (> threshold)\n",
        "           - AND total players < max_players\n",
        "        \"\"\"\n",
        "        self.frame_count += 1\n",
        "\n",
        "        # Extract features\n",
        "        det_features = []\n",
        "        if frame is not None:\n",
        "            for det in detections:\n",
        "                feat = self._extract_features(frame, det[:4])\n",
        "                det_features.append(feat)\n",
        "        else:\n",
        "            det_features = [None] * len(detections)\n",
        "\n",
        "\n",
        "        for track in self.active_tracks.values():\n",
        "            track['predicted_box'] = self._predict_next_position(track)\n",
        "\n",
        "        # === PHASE 1: MATCH TO ACTIVE TRACKS ===\n",
        "        # Use GREEDY MATCHING instead of Hungarian for stability\n",
        "        # Strategy: Match high-confidence tracks FIRST (they get priority)\n",
        "\n",
        "        matched_pairs = []\n",
        "        unmatched_detections = list(range(len(detections)))\n",
        "        unmatched_tracks = list(self.active_tracks.keys())\n",
        "\n",
        "        if len(detections) > 0 and len(self.active_tracks) > 0:\n",
        "            track_ids = list(self.active_tracks.keys())\n",
        "            track_confidences = [self.track_confidence.get(tid, 0.3) for tid in track_ids]\n",
        "            sorted_indices = np.argsort(track_confidences)[::-1]  # Descending order\n",
        "            sorted_track_ids = [track_ids[i] for i in sorted_indices]\n",
        "\n",
        "            # GREEDY MATCHING: Each stable track claims its best detection\n",
        "            for track_id in sorted_track_ids:\n",
        "                if track_id not in unmatched_tracks:\n",
        "                    continue\n",
        "\n",
        "                track = self.active_tracks[track_id]\n",
        "                confidence = self.track_confidence.get(track_id, 0.3)\n",
        "\n",
        "                best_det_idx = None\n",
        "                best_score = -999\n",
        "                best_distance = 999\n",
        "\n",
        "                # Find best detection for this track\n",
        "                for det_idx in unmatched_detections:\n",
        "                    det = detections[det_idx]\n",
        "                    score, distance = self._calculate_match_score(det, track, det_features[det_idx])\n",
        "\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_distance = distance\n",
        "                        best_det_idx = det_idx\n",
        "\n",
        "\n",
        "                if best_det_idx is not None:\n",
        "\n",
        "                    score_threshold = 0.25 - (confidence * 0.15)  # 0.25 down to 0.10\n",
        "                    distance_threshold = 200 + (confidence * 150)   # 200 up to 350px\n",
        "\n",
        "\n",
        "                    if confidence > 0.8:\n",
        "                        score_threshold = 0.05  # Almost always accept\n",
        "                        distance_threshold = 400  # Very large distance OK\n",
        "\n",
        "                    if best_score > score_threshold and best_distance < distance_threshold:\n",
        "                        matched_pairs.append((best_det_idx, track_id))\n",
        "                        unmatched_detections.remove(best_det_idx)\n",
        "                        unmatched_tracks.remove(track_id)\n",
        "\n",
        "\n",
        "                        self.last_match_quality[track_id] = best_score\n",
        "\n",
        "\n",
        "        for det_idx, track_id in matched_pairs:\n",
        "            det = detections[det_idx]\n",
        "            box = np.array(det[:4])\n",
        "\n",
        "            track = self.active_tracks[track_id]\n",
        "\n",
        "            # Adaptive smoothing based on movement speed\n",
        "            prev_box = track['box']\n",
        "            if isinstance(prev_box, list):\n",
        "                prev_box = np.array(prev_box)\n",
        "            else:\n",
        "                prev_box = np.array(prev_box)\n",
        "\n",
        "            movement = np.linalg.norm(self._get_center(box) - self._get_center(prev_box))\n",
        "\n",
        "            if movement > 80:  # Fast movement\n",
        "                smoothed_box = 0.3 * prev_box + 0.7 * box\n",
        "            else:  # Slow movement\n",
        "                smoothed_box = 0.7 * prev_box + 0.3 * box\n",
        "\n",
        "            track['box'] = smoothed_box.tolist()\n",
        "            track['position_history'].append(smoothed_box)\n",
        "            track['confidence'] = det[4] if len(det) > 4 else 1.0\n",
        "            track['frames_tracked'] += 1\n",
        "            track['frames_lost'] = 0\n",
        "\n",
        "            # Update appearance with retention\n",
        "            if det_features[det_idx] is not None:\n",
        "                if track['appearance'] is not None:\n",
        "                    track['appearance'] = 0.85 * track['appearance'] + 0.15 * det_features[det_idx]\n",
        "                else:\n",
        "                    track['appearance'] = det_features[det_idx]\n",
        "\n",
        "            # Limit history\n",
        "            if len(track['position_history']) > self.memory_frames:\n",
        "                track['position_history'].popleft()\n",
        "\n",
        "        # Age unmatched active tracks\n",
        "        for track_id in unmatched_tracks:\n",
        "            self.active_tracks[track_id]['frames_lost'] += 1\n",
        "\n",
        "            # Get current confidence\n",
        "            current_confidence = self.track_confidence.get(track_id, 0.3)\n",
        "\n",
        "            if current_confidence > 0.8:\n",
        "                confidence_decay = 0.01  # Very slow decay for stable tracks\n",
        "                max_frames_lost = 80     # Wait longer before removing\n",
        "            elif current_confidence > 0.6:\n",
        "                confidence_decay = 0.03\n",
        "                max_frames_lost = 60\n",
        "            else:\n",
        "                confidence_decay = 0.05\n",
        "                max_frames_lost = 40\n",
        "\n",
        "            # Decrease confidence when track is lost\n",
        "            self.track_confidence[track_id] = max(0.3, current_confidence - confidence_decay)\n",
        "\n",
        "            # Move to memory bank based on confidence-adjusted threshold\n",
        "            if self.active_tracks[track_id]['frames_lost'] > max_frames_lost:\n",
        "                self.memory_bank[track_id] = self.active_tracks[track_id]\n",
        "                self.memory_bank[track_id]['lost_at_frame'] = self.frame_count\n",
        "                del self.active_tracks[track_id]\n",
        "\n",
        "        # === PHASE 2: RECOVERY FROM MEMORY BANK ===\n",
        "        for det_idx in unmatched_detections[:]:\n",
        "            det = detections[det_idx]\n",
        "            det_box = np.array(det[:4])\n",
        "            det_feat = det_features[det_idx]\n",
        "\n",
        "            best_match_id = None\n",
        "            best_score = 0.25  # Lower threshold for recovery\n",
        "\n",
        "            for mem_id, mem_track in self.memory_bank.items():\n",
        "                frames_since_lost = self.frame_count - mem_track['lost_at_frame']\n",
        "\n",
        "                # Only recover recent losses (< 3 seconds)\n",
        "                if frames_since_lost > 150:\n",
        "                    continue\n",
        "\n",
        "                # Calculate match score\n",
        "                mem_box = mem_track['box']\n",
        "                if isinstance(mem_box, list):\n",
        "                    mem_box = np.array(mem_box)\n",
        "\n",
        "                distance = self._calculate_distance(det_box, mem_box)\n",
        "                appearance_sim = self._compare_features(det_feat, mem_track['appearance'])\n",
        "\n",
        "                # Recovery focuses on appearance and reasonable distance\n",
        "                score = 0.6 * appearance_sim + 0.4 * max(0, 1 - distance / 400)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_match_id = mem_id\n",
        "\n",
        "            # Recover track\n",
        "            if best_match_id is not None:\n",
        "                self.active_tracks[best_match_id] = self.memory_bank[best_match_id]\n",
        "                self.active_tracks[best_match_id]['box'] = det_box.tolist()\n",
        "                self.active_tracks[best_match_id]['frames_lost'] = 0\n",
        "                self.active_tracks[best_match_id]['position_history'].append(det_box)\n",
        "\n",
        "                # Restore confidence (but reduced)\n",
        "                if best_match_id in self.track_confidence:\n",
        "                    self.track_confidence[best_match_id] = max(0.4, self.track_confidence[best_match_id] - 0.1)\n",
        "                else:\n",
        "                    self.track_confidence[best_match_id] = 0.4\n",
        "\n",
        "                if det_feat is not None:\n",
        "                    if self.active_tracks[best_match_id]['appearance'] is not None:\n",
        "                        self.active_tracks[best_match_id]['appearance'] = (\n",
        "                            0.7 * self.active_tracks[best_match_id]['appearance'] + 0.3 * det_feat\n",
        "                        )\n",
        "                    else:\n",
        "                        self.active_tracks[best_match_id]['appearance'] = det_feat\n",
        "\n",
        "                del self.memory_bank[best_match_id]\n",
        "                unmatched_detections.remove(det_idx)\n",
        "\n",
        "        # === PHASE 3: CREATE NEW IDs (STRICT RULES) ===\n",
        "        for det_idx in unmatched_detections:\n",
        "            det = detections[det_idx]\n",
        "            det_box = np.array(det[:4])\n",
        "\n",
        "            # RULE 1: Check if we're at max capacity\n",
        "            if len(self.active_tracks) >= self.max_players:\n",
        "                continue  # Don't create new ID\n",
        "\n",
        "            # RULE 2: Must be far from ALL existing players\n",
        "            if not self._is_far_from_all_tracks(det_box, self.spatial_threshold):\n",
        "                continue  # Too close to existing player\n",
        "\n",
        "            # RULE 3: Check memory bank too\n",
        "            too_close_to_memory = False\n",
        "            for mem_track in self.memory_bank.values():\n",
        "                mem_box = mem_track['box']\n",
        "                if isinstance(mem_box, list):\n",
        "                    mem_box = np.array(mem_box)\n",
        "                distance = self._calculate_distance(det_box, mem_box)\n",
        "                if distance < self.spatial_threshold * 0.7:  # Even stricter for memory\n",
        "                    too_close_to_memory = True\n",
        "                    break\n",
        "\n",
        "            if too_close_to_memory:\n",
        "                continue\n",
        "\n",
        "            # All checks passed - create new track\n",
        "            track_id = self.next_id\n",
        "            self.next_id += 1\n",
        "\n",
        "            self.active_tracks[track_id] = {\n",
        "                'box': det_box.tolist(),\n",
        "                'predicted_box': det_box.tolist(),\n",
        "                'position_history': deque([det_box], maxlen=self.memory_frames),\n",
        "                'appearance': det_features[det_idx],\n",
        "                'confidence': det[4] if len(det) > 4 else 1.0,\n",
        "                'frames_tracked': 1,\n",
        "                'frames_lost': 0\n",
        "            }\n",
        "\n",
        "            # Initialize new track with LOW confidence (must prove itself)\n",
        "            self.track_confidence[track_id] = 0.3\n",
        "            self.last_match_quality[track_id] = 0.5\n",
        "\n",
        "        # Clean old memory\n",
        "        to_delete = []\n",
        "        for mem_id, mem_track in self.memory_bank.items():\n",
        "            if self.frame_count - mem_track['lost_at_frame'] > 200:  # 4 seconds\n",
        "                to_delete.append(mem_id)\n",
        "        for mem_id in to_delete:\n",
        "            del self.memory_bank[mem_id]\n",
        "\n",
        "        # Return results\n",
        "        results = []\n",
        "        for track_id, track in self.active_tracks.items():\n",
        "            box = track['box']\n",
        "            results.append([box[0], box[1], box[2], box[3], track_id])\n",
        "\n",
        "        return results\n",
        "\n",
        "print(\"‚úì Spatial Anchored Tracker defined!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPLETE END TO END PIPELINE"
      ],
      "metadata": {
        "id": "TTGi1y-KH5Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CricketPlayerTrackingPipeline:\n",
        "    def __init__(self, model_name='yolov8x.pt'):\n",
        "        print(f\"Loading YOLO model: {model_name}...\")\n",
        "        from ultralytics import YOLO\n",
        "        self.model = YOLO(model_name)\n",
        "\n",
        "        # Spatial Anchored Tracker - prevents ID explosion\n",
        "        self.tracker = SpatialAnchoredTracker(\n",
        "            max_players=12,           # Max 12 players on field\n",
        "            spatial_threshold=300,    # 300px minimum for new ID\n",
        "            memory_frames=20          # Remember 20 frames\n",
        "        )\n",
        "        print(\"‚úì Model and Spatial Anchored Tracker initialized!\")\n",
        "\n",
        "    def detect_players(self, frame):\n",
        "        \"\"\"Detect players using YOLO\"\"\"\n",
        "        results = self.model(frame, classes=[0], verbose=False)[0]\n",
        "\n",
        "        detections = []\n",
        "        if len(results.boxes) > 0:\n",
        "            boxes = results.boxes.xyxy.cpu().numpy()\n",
        "            confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "            for box, conf in zip(boxes, confidences):\n",
        "                if conf > 0.45:  # Balanced threshold\n",
        "                    detections.append([\n",
        "                        float(box[0]), float(box[1]),\n",
        "                        float(box[2]), float(box[3]),\n",
        "                        float(conf)\n",
        "                    ])\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def draw_tracking_results(self, frame, tracked_objects):\n",
        "        \"\"\"Draw tracking results with stable IDs\"\"\"\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        colors = [\n",
        "            (0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0),\n",
        "            (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 128, 0),\n",
        "            (0, 128, 255), (128, 255, 0), (255, 0, 128), (200, 100, 50)\n",
        "        ]\n",
        "\n",
        "        for obj in tracked_objects:\n",
        "            x1, y1, x2, y2, track_id = obj\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            color = colors[int(track_id) % len(colors)]\n",
        "\n",
        "            # Thick box\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 4)\n",
        "\n",
        "            # Large ID label\n",
        "            label = f\"Player {int(track_id)}\"\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 1.2\n",
        "            thickness = 3\n",
        "\n",
        "            (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
        "\n",
        "            # Background\n",
        "            cv2.rectangle(\n",
        "                annotated_frame,\n",
        "                (x1, y1 - text_height - 20),\n",
        "                (x1 + text_width + 20, y1),\n",
        "                color,\n",
        "                -1\n",
        "            )\n",
        "\n",
        "            # Text\n",
        "            cv2.putText(\n",
        "                annotated_frame,\n",
        "                label,\n",
        "                (x1 + 10, y1 - 10),\n",
        "                font,\n",
        "                font_scale,\n",
        "                (255, 255, 255),\n",
        "                thickness\n",
        "            )\n",
        "\n",
        "            # Center point\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "            cv2.circle(annotated_frame, (center_x, center_y), 8, color, -1)\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "    def process_video(self, input_path, output_path, skip_frames=1):\n",
        "        \"\"\"Process video with spatial anchored tracking\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üèè SPATIAL ANCHORED CRICKET TRACKING\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video: {input_path}\")\n",
        "\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        print(f\"Video: {width}x{height} @ {fps}fps\")\n",
        "        print(f\"Total: {total_frames} frames ({total_frames/fps:.1f}s)\")\n",
        "        print(f\"Processing every {skip_frames} frame(s)\\n\")\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        last_tracked = []\n",
        "\n",
        "        # Reset tracker\n",
        "        self.tracker = SpatialAnchoredTracker(\n",
        "            max_players=12,\n",
        "            spatial_threshold=300,\n",
        "            memory_frames=20\n",
        "        )\n",
        "\n",
        "        max_id_seen = 0\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "                if frame_count % skip_frames == 0:\n",
        "                    detections = self.detect_players(frame)\n",
        "                    tracked_objects = self.tracker.update(detections, frame=frame)\n",
        "\n",
        "                    # Track max ID\n",
        "                    if tracked_objects:\n",
        "                        current_max = max(int(obj[4]) for obj in tracked_objects)\n",
        "                        max_id_seen = max(max_id_seen, current_max)\n",
        "\n",
        "                    annotated_frame = self.draw_tracking_results(frame, tracked_objects)\n",
        "                    last_tracked = tracked_objects\n",
        "\n",
        "                    if frame_count % 50 == 0:\n",
        "                        progress = (frame_count / total_frames) * 100\n",
        "                        active = len(self.tracker.active_tracks)\n",
        "                        memory = len(self.tracker.memory_bank)\n",
        "\n",
        "                        # Show confidence levels of active tracks\n",
        "                        high_conf = sum(1 for tid in self.tracker.active_tracks.keys()\n",
        "                                       if self.tracker.track_confidence.get(tid, 0) > 0.8)\n",
        "\n",
        "                        print(f\"‚è≥ {progress:.1f}% | Frame {frame_count}/{total_frames} | \"\n",
        "                              f\"Active: {active} (Stable: {high_conf}) | Memory: {memory} | Max ID: {max_id_seen}\")\n",
        "                else:\n",
        "                    annotated_frame = self.draw_tracking_results(frame, last_tracked)\n",
        "\n",
        "                out.write(annotated_frame)\n",
        "\n",
        "        finally:\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"‚úÖ COMPLETE!\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Max ID reached: {max_id_seen}\")\n",
        "        print(f\"Output: {output_path}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(\"‚úì Spatial Anchored Pipeline defined!\")"
      ],
      "metadata": {
        "id": "JjFpXJjMAjD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "USER INPUT AND RUNNING THE PIPELINE. WHEN PROMPTED JUST ENTER THE FILE PATH"
      ],
      "metadata": {
        "id": "W0ZFc9RKHt_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\" SPATIAL ANCHORED CRICKET TRACKING\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "video_path = input(\"Enter video path: \").strip()\n",
        "\n",
        "if os.path.isdir(video_path):\n",
        "    print(f\"\\n‚ö†Ô∏è  Folder detected!\")\n",
        "    try:\n",
        "        files = os.listdir(video_path)\n",
        "        video_files = [f for f in files if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "\n",
        "        if video_files:\n",
        "            print(\"\\nAvailable videos:\")\n",
        "            for i, vf in enumerate(video_files, 1):\n",
        "                print(f\"  {i}. {vf}\")\n",
        "\n",
        "            choice = input(f\"\\nSelect (1-{len(video_files)}): \").strip()\n",
        "            idx = int(choice) - 1\n",
        "            video_path = os.path.join(video_path, video_files[idx])\n",
        "    except:\n",
        "        print(\"Error reading folder\")\n",
        "        raise SystemExit\n",
        "\n",
        "if not os.path.isfile(video_path):\n",
        "    print(f\"\\n‚ùå File not found: {video_path}\")\n",
        "    raise SystemExit\n",
        "\n",
        "print(f\"\\n‚úÖ Video: {video_path}\")\n",
        "\n",
        "video_name = Path(video_path).stem\n",
        "output_path = f\"/content/output_{video_name}_spatial_anchored.mp4\"\n",
        "\n",
        "skip_input = input(\"\\nFrame skip (1-3, default=1): \").strip()\n",
        "skip_frames = int(skip_input) if skip_input.isdigit() else 1\n",
        "\n",
        "print(\"\\n Processing...\\n\")\n",
        "\n",
        "try:\n",
        "    pipeline = CricketPlayerTrackingPipeline(model_name='yolov8x.pt')\n",
        "    pipeline.process_video(video_path, output_path, skip_frames=skip_frames)\n",
        "\n",
        "    print(\"\\n SUCCESS!\")\n",
        "    print(f\"Output: {output_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "ppTdM-1WAqzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTOMATIC DOWNLOADING"
      ],
      "metadata": {
        "id": "qKR6JdgmHozr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: DOWNLOAD THE OUTPUT FILES\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "print(\"üì• Downloading output...\\n\")\n",
        "\n",
        "try:\n",
        "    output_files = glob.glob(\"/content/output_*_spatial_anchored.mp4\")\n",
        "\n",
        "    if output_files:\n",
        "        latest = max(output_files, key=os.path.getctime)\n",
        "        size_mb = os.path.getsize(latest) / (1024*1024)\n",
        "\n",
        "        print(f\"File: {os.path.basename(latest)} ({size_mb:.1f} MB)\")\n",
        "        print(\"Starting download...\\n\")\n",
        "\n",
        "        files.download(latest)\n",
        "        print(\"‚úÖ Download started!\")\n",
        "    else:\n",
        "        print(\" No output files found\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "d4S_TndQAuXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THANK YOU FOR USING MY NOTEBOOK. PLEASE GIVE YOUR VALUABLE FEEDBACK."
      ],
      "metadata": {
        "id": "YEjX4Y_kEG6m"
      }
    }
  ]
}